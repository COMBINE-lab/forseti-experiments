params {
    mode = null
    // input files
    input_files {
        ref_sheet = "${projectDir}/input_files/ref_sheet.csv"
        sample_sheet = "${projectDir}/input_files/sample_url_sheet.csv"
    }

    fastp {
        qualified_quality_phred = 30
        unqualified_percent_limit = 30
        complexity_threshold = 30
    }

    simulation {
        read_len = 91
        max_num_fail_per_read=10000
        random_seed = 1
    }
    mlp {
        random_seed = 1
        snr_len = 6
        snr_mismatch = 1
    }
    spline {
        random_seed = 10
    }
    eval {
        max_frag_len = 1000
        mlp_path = "${params.output_dir}/models/mlp_model/mlp.pkl"
        spline_path = "${params.output_dir}/models/spline_model/spline_model.pkl"
    }

    polya_min_length = 6
    polya_max_mismatch = 0
    exon_dist_thresh = 1000
    
    whitelist_dir = "${projectDir}/data/whitelist"
    timecmd = "/usr/bin/time"
    output_dir = "${projectDir}/workflow_output"
    data_dir  = "${projectDir}/data"
    qos = "highmem"
    //     high  1-00:00:00     cpu=16,gres/gpu=4,mem=128G                                          
    //  highmem 21-00:00:00                  cpu=32,mem=2T                
    num_threads = 16
    gb_mem = 128
    num_threads_large = 32
    gb_mem_large = 2000

}

// workDir = params.work_dir

// cleanup = true

process {
    executor = "slurm"
    scratch = false
    cpus = params.num_threads
    memory = "${params.gb_mem}G"
    clusterOptions = "--partition=cbcb --qos=${params.qos} --account=cbcb --time=12:00:00"
    conda = "${projectDir}/conda_envs/ext_r1_env.yml"

    // local can be used for very small jobs, like write log files
    withLabel: local {
        executor = "local"
        cpus = 1
        memory = "1.GB"
    }
    withLabel: r {
        conda = "${projectDir}/conda_envs/conda-r.yml"
    }
    withName: "sim_.*" {
        memory = "${params.gb_mem_large}.GB"
        cpus = params.num_threads_large
        conda = "${projectDir}/conda_envs/simulation.yml"
    }
    withName: "eval_.*" {
        memory = "${params.gb_mem_large}.GB"
        cpus = params.num_threads_large
    }
}


conda {
    enabled = true
    useMamba = true
    cacheDir = "${projectDir}/conda_envs/cache"
    createTimeout = "240 min"
}

trace {
  enabled = true
  overwrite = true
  file = 'pipeline_trace.txt'
  fields = 'task_id,name,tag,status,exit,realtime,%cpu,%mem,rss,peak_rss,realtime'
}
